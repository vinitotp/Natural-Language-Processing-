{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP Assignment 2 final Code.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "XZ0vp8Duq_qn",
        "colab_type": "code",
        "outputId": "8089c319-b4d9-48de-c30f-47b408d78a02",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 666
        }
      },
      "source": [
        "!python -m spacy download en\n",
        "!pip install torch\n",
        "import spacy\n",
        "spacy.load('en')\n",
        "import torch\n",
        "from torchtext import data\n",
        "from torchtext import datasets\n",
        "import random\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "import torch\n",
        "from torchtext import data\n",
        "import spacy\n",
        "spacy.load('en')\n",
        "import nltk \n",
        "import random \n",
        "from nltk.tokenize import word_tokenize\n",
        "nltk.download('punkt') \n",
        "nltk.download('stopwords') \n",
        "nltk.download('movie_reviews') \n",
        "nltk.download('wordnet') "
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: en_core_web_sm==2.2.5 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.5/en_core_web_sm-2.2.5.tar.gz#egg=en_core_web_sm==2.2.5 in /usr/local/lib/python3.6/dist-packages (2.2.5)\n",
            "Requirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.6/dist-packages (from en_core_web_sm==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (4.38.0)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.2)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.6.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (46.0.0)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.0.3)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.2)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.21.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.18.2)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2019.11.28)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2.8)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.1.0)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;2m✔ Linking successful\u001b[0m\n",
            "/usr/local/lib/python3.6/dist-packages/en_core_web_sm -->\n",
            "/usr/local/lib/python3.6/dist-packages/spacy/data/en\n",
            "You can now load the model via spacy.load('en')\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (1.4.0)\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package movie_reviews to /root/nltk_data...\n",
            "[nltk_data]   Package movie_reviews is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wxqIdcUCrKDf",
        "colab_type": "code",
        "outputId": "f9e99396-a944-4f50-a49a-f3794c0372cc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        }
      },
      "source": [
        "import csv\n",
        "import urllib.request as urllib2\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "url = 'https://raw.githubusercontent.com/cacoderquan/Sentiment-Analysis-on-the-Rotten-Tomatoes-movie-review-dataset/master/train.tsv'\n",
        "response = urllib2.urlopen(url)\n",
        "dataframe1 = pd.read_csv(response,delimiter='\\t',encoding='utf-8')\n",
        "dataframe1 = dataframe1.sample(frac=1).reset_index(drop=True)\n",
        "dataframe1.head(10)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PhraseId</th>\n",
              "      <th>SentenceId</th>\n",
              "      <th>Phrase</th>\n",
              "      <th>Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>21851</td>\n",
              "      <td>978</td>\n",
              "      <td>its own placid way</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>141958</td>\n",
              "      <td>7699</td>\n",
              "      <td>in the foot</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>30126</td>\n",
              "      <td>1398</td>\n",
              "      <td>' it also rocks .</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>46438</td>\n",
              "      <td>2258</td>\n",
              "      <td>a neat twist ,</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>60692</td>\n",
              "      <td>3066</td>\n",
              "      <td>seem bound and determined to duplicate Bela Lu...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>19160</td>\n",
              "      <td>840</td>\n",
              "      <td>behind it</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>34495</td>\n",
              "      <td>1620</td>\n",
              "      <td>coming back</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>95803</td>\n",
              "      <td>5005</td>\n",
              "      <td>funny , harmless and</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>2094</td>\n",
              "      <td>80</td>\n",
              "      <td>cinematic experience</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>72068</td>\n",
              "      <td>3679</td>\n",
              "      <td>find ourselves surprised at how much we care a...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   PhraseId  ...  Sentiment\n",
              "0     21851  ...          2\n",
              "1    141958  ...          2\n",
              "2     30126  ...          3\n",
              "3     46438  ...          3\n",
              "4     60692  ...          1\n",
              "5     19160  ...          2\n",
              "6     34495  ...          2\n",
              "7     95803  ...          3\n",
              "8      2094  ...          3\n",
              "9     72068  ...          3\n",
              "\n",
              "[10 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kYQpkx1qwEfB",
        "colab_type": "code",
        "outputId": "96ebd0c9-eec2-4a26-b0b4-471db4ef8498",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "X1, X2, Y1, Y2 = train_test_split(dataframe1 ['Phrase'], dataframe1 ['Sentiment'], test_size=0.3, random_state=2003)\n",
        "documents=[]\n",
        "X1 = np.array(X1.values.tolist())\n",
        "Y1 = np.array(Y1.values.tolist())\n",
        "for i in range(len(X1)):\n",
        "  documents.append([list(word_tokenize(X1[i])), Y1[i]]) \n",
        "\n",
        "X2 = np.array(X2.values.tolist())\n",
        "Y2 = np.array(Y2.values.tolist())\n",
        "for i in range(len(X2)):\n",
        "  documents.append([list(word_tokenize(X2[i])), Y2[i]]) \n",
        "\n",
        "documents[0]"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['jumps',\n",
              "  'to',\n",
              "  'the',\n",
              "  'head',\n",
              "  'of',\n",
              "  'the',\n",
              "  'class',\n",
              "  'of',\n",
              "  'women',\n",
              "  \"'s\",\n",
              "  'films'],\n",
              " 4]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EPDTjGrdzOYM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nltk.corpus import stopwords \n",
        "from nltk.stem import WordNetLemmatizer, PorterStemmer, LancasterStemmer \n",
        "stem1 = PorterStemmer() \n",
        "stem2=LancasterStemmer() \n",
        "word_lemma = WordNetLemmatizer() \n",
        "stop_english = stopwords.words(\"english\") \n",
        "punct=\"?:!.,;'\\\"-()\"\n",
        "r_stop = True\n",
        "useStem = False\n",
        "useLemma = False\n",
        "removePuncs = True\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-NOj8KmZzRSW",
        "colab_type": "code",
        "outputId": "04abb404-b29e-479e-d26b-a44b2c0b3a3f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "for l in range(len(documents)):                   \n",
        "  label = documents[l][1]                          \n",
        "  newReview = []                                   \n",
        "  for w in documents[l][0]:                  \n",
        "    newWord = w                                    \n",
        "    if r_stop and (w in stop_english):  \n",
        "      continue                                    \n",
        "    if removePuncs and (w in punct):        \n",
        "      continue                                    \n",
        "    if useStem:\n",
        "      newWord = stem2.stem(newWord) \n",
        "    if useLemma: \n",
        "      newWord = word_lemma.lemmatize(newWord) \n",
        "    newReview.append(newWord)                     \n",
        "  documents[l] = (newReview, label)             \n",
        "  documents[l] = (' '.join(newReview), label) \n",
        "\n",
        "print(documents[0])"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(\"jumps head class women 's films\", 4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IRaO3eghzTum",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataframe1 = pd.DataFrame(documents, columns=['text', 'sentiment']) \n",
        "dataframe1.head()\n",
        "\n",
        "X1, X2, Y1, Y2 = train_test_split(dataframe1['text'],  dataframe1['sentiment'], test_size=0.3, random_state=2003)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2IBmwTNbzYwy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer , TfidfVectorizer\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "vectorizer = TfidfVectorizer(max_features = 2500)\n",
        "X = vectorizer.fit_transform(dataframe1[\"text\"]) \n",
        "Y = dataframe1['sentiment'] \n",
        "X1 = vectorizer.transform(X1).toarray()\n",
        "Y1 = Y1 \n",
        "X2 = vectorizer.transform(X2).toarray()\n",
        "Y2 = Y2\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cD1l-eDJzbda",
        "colab_type": "code",
        "outputId": "a7d00ee1-60be-4fec-9fa8-d21357d0b089",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "Y2"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "13510     2\n",
              "61932     2\n",
              "82549     0\n",
              "137718    2\n",
              "121990    2\n",
              "         ..\n",
              "94224     3\n",
              "135456    2\n",
              "154729    2\n",
              "23031     2\n",
              "57870     3\n",
              "Name: sentiment, Length: 46818, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HdSkmG-8zeai",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv1D, MaxPooling1D\n",
        "from keras import backend as K"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G9AJ1CfRziwQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "count_classes = 5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RgOl69ETzlED",
        "colab_type": "code",
        "outputId": "f14826ef-18cc-41cb-88b0-e171fc7d0d4a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X1.shape"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(109242, 2500)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_7kYbumvzn7J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Y1 = keras.utils.to_categorical(Y1, count_classes)\n",
        "Y2 = keras.utils.to_categorical(Y2, count_classes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fqmv3Pe4zqUF",
        "colab_type": "code",
        "outputId": "d3389b1c-b841-4c7a-96e1-8b8850e4e92e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "Y2"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 1., 0., 0.],\n",
              "       [0., 0., 1., 0., 0.],\n",
              "       [1., 0., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 1., 0., 0.],\n",
              "       [0., 0., 1., 0., 0.],\n",
              "       [0., 0., 0., 1., 0.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yi6tTwc7zvFF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Conv1D(filters=64, kernel_size=3,\n",
        "                 activation='relu',\n",
        "                 input_shape=(2500,1)))\n",
        "model.add(Conv1D(128, kernel_size=3, activation='relu'))\n",
        "model.add(Conv1D(128, kernel_size=3, activation='relu'))\n",
        "model.add(Conv1D(128, kernel_size=3, activation='relu'))\n",
        "model.add(Conv1D(128, kernel_size=3, activation='relu'))\n",
        "model.add(Conv1D(128, kernel_size=3, activation='relu'))\n",
        "model.add(MaxPooling1D(pool_size=2))\n",
        "model.add(MaxPooling1D(pool_size=2))\n",
        "model.add(MaxPooling1D(pool_size=2))\n",
        "model.add(MaxPooling1D(pool_size=2))\n",
        "model.add(MaxPooling1D(pool_size=2))\n",
        "model.add(MaxPooling1D(pool_size=2))\n",
        "model.add(Dropout(rate = 0.25))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(count_classes, activation='softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J_egBiwv-lDL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def recall_m(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "    recall = true_positives / (possible_positives + K.epsilon())\n",
        "    return recall\n",
        "\n",
        "def precision_m(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "    precision = true_positives / (predicted_positives + K.epsilon())\n",
        "    return precision\n",
        "\n",
        "def f1_m(y_true, y_pred):\n",
        "    precision = precision_m(y_true, y_pred)\n",
        "    recall = recall_m(y_true, y_pred)\n",
        "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mDOzfqewAlzT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss=keras.losses.categorical_crossentropy,\n",
        "              optimizer=keras.optimizers.Adam(),\n",
        "              metrics=['accuracy',recall_m,precision_m,f1_m])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fHwDSeMdz2Zs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X1 = X1.reshape(X1.shape[0], X1.shape[1], 1)\n",
        "X2 = X2.reshape(X2.shape[0], X2.shape[1], 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QQyw6xOEz5Tk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.fit(X1, Y1,\n",
        "          batch_size=128,\n",
        "          epochs=50)\n",
        "# _, accuracy = model.evaluate(X_test, Y_test, batch_size=batch_size, verbose=0)\n",
        "score = model.evaluate(X2, Y2, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])\n",
        "loss, accuracy, f1_score, precision, recall = model.evaluate(X2, Y2, verbose=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y1BnA6XDtsmt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import load_model\n",
        "model.save(\"model.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}